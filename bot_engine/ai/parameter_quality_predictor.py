#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ML –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏

–û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö/–Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç:
- –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –û–∂–∏–¥–∞–µ–º—ã–π Win Rate
- –û–∂–∏–¥–∞–µ–º—ã–π PnL

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–º–µ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω—ã—Ö
"""

import os
import json
import logging
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib

logger = logging.getLogger('AI.ParameterQualityPredictor')


class ParameterQualityPredictor:
    """
    ML –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏
    """
    
    def __init__(self, data_dir: str = 'data/ai'):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
        
        self.model_file = os.path.join(data_dir, 'parameter_quality_predictor.pkl')
        self.scaler_file = os.path.join(data_dir, 'parameter_quality_scaler.pkl')
        self.training_data_file = os.path.join(data_dir, 'parameter_training_data.json')
        
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—Å—Ç—å
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            if os.path.exists(self.model_file) and os.path.exists(self.scaler_file):
                self.model = joblib.load(self.model_file)
                self.scaler = joblib.load(self.scaler_file)
                self.is_trained = True
                logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.is_trained = False
    
    def _save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            if self.model:
                joblib.dump(self.model, self.model_file)
                joblib.dump(self.scaler, self.scaler_file)
                logger.info("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def _extract_features(self, rsi_params: Dict, risk_params: Optional[Dict] = None) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            rsi_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RSI
            risk_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            –ú–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        features = [
            rsi_params.get('oversold', 29),
            rsi_params.get('overbought', 71),
            rsi_params.get('exit_long_with_trend', 65),
            rsi_params.get('exit_long_against_trend', 60),
            rsi_params.get('exit_short_with_trend', 35),
            rsi_params.get('exit_short_against_trend', 40),
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Å–∫-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if risk_params:
            features.extend([
                risk_params.get('stop_loss', 15.0),
                risk_params.get('take_profit', 20.0),
                risk_params.get('trailing_stop_activation', 30.0),
                risk_params.get('trailing_stop_distance', 5.0),
            ])
        else:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ—Ç
            features.extend([0, 0, 0, 0])
        
        return np.array(features).reshape(1, -1)
    
    def add_training_sample(self, rsi_params: Dict, win_rate: float, total_pnl: float,
                           trades_count: int, risk_params: Optional[Dict] = None,
                           symbol: Optional[str] = None, blocked: bool = False):
        """
        –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–∑–µ—Ü –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            rsi_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RSI
            win_rate: Win Rate (0-100)
            total_pnl: Total PnL
            trades_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫
            risk_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
            symbol: –°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã
            blocked: –ë—ã–ª–∏ –ª–∏ –≤—Ö–æ–¥—ã –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            training_data = []
            if os.path.exists(self.training_data_file):
                with open(self.training_data_file, 'r', encoding='utf-8') as f:
                    training_data = json.load(f)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ (target –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
            # –ö–∞—á–µ—Å—Ç–≤–æ = –∫–æ–º–±–∏–Ω–∞—Ü–∏—è win_rate, pnl, trades_count
            # –ï—Å–ª–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ - –∫–∞—á–µ—Å—Ç–≤–æ = 0
            if blocked or trades_count == 0:
                quality = 0.0
            else:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
                win_rate_norm = win_rate / 100.0  # 0-1
                pnl_norm = min(max(total_pnl / 1000.0, -1), 1)  # -1 –¥–æ 1 (1000 USDT = 1.0)
                trades_norm = min(trades_count / 50.0, 1)  # 0-1 (50 —Å–¥–µ–ª–æ–∫ = 1.0)
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
                quality = (
                    win_rate_norm * 0.5 +
                    pnl_norm * 0.3 +
                    trades_norm * 0.2
                )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–µ—Ü
            sample = {
                'rsi_params': rsi_params,
                'risk_params': risk_params or {},
                'win_rate': win_rate,
                'total_pnl': total_pnl,
                'trades_count': trades_count,
                'quality': quality,
                'blocked': blocked,
                'symbol': symbol,
                'timestamp': datetime.now().isoformat()
            }
            
            training_data.append(sample)
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5000 –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(training_data) > 5000:
                training_data = training_data[-5000:]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(self.training_data_file, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"üìù –î–æ–±–∞–≤–ª–µ–Ω –æ–±—Ä–∞–∑–µ—Ü –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (quality: {quality:.3f}, win_rate: {win_rate:.1f}%)")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞: {e}")
    
    def train(self, min_samples: int = 50) -> Optional[Dict[str, Any]]:
        """
        –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            min_samples: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ None –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
        """
        try:
            if not os.path.exists(self.training_data_file):
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return None
            
            with open(self.training_data_file, 'r', encoding='utf-8') as f:
                training_data = json.load(f)
            
            samples_count = len(training_data)
            if samples_count < min_samples:
                logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {samples_count}/{min_samples}")
                return {
                    'success': False,
                    'samples_count': samples_count,
                    'min_samples_required': min_samples,
                    'reason': 'not_enough_samples'
                }
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            X = []
            y = []
            
            for sample in training_data:
                features = self._extract_features(
                    sample['rsi_params'],
                    sample.get('risk_params')
                )
                X.append(features[0])
                y.append(sample['quality'])
            
            X = np.array(X)
            y = np.array(y)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            X_scaled = self.scaler.fit_transform(X)
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = GradientBoostingRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42,
                n_iter_no_change=10
            )
            
            # –û–±—É—á–∞–µ–º
            logger.info(f"üéì –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ {len(X)} –æ–±—Ä–∞–∑—Ü–∞—Ö...")
            self.model.fit(X_scaled, y)
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            train_score = self.model.score(X_scaled, y)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞! R¬≤ score: {train_score:.3f}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ–±—Ä–∞–∑—Ü–æ–≤
            avg_quality = float(np.mean(y))
            max_quality = float(np.max(y))
            min_quality = float(np.min(y))
            blocked_count = sum(1 for s in training_data if s.get('blocked', False))
            
            self.is_trained = True
            self._save_model()
            
            return {
                'success': True,
                'samples_count': samples_count,
                'r2_score': float(train_score),
                'avg_quality': avg_quality,
                'max_quality': max_quality,
                'min_quality': min_quality,
                'blocked_samples': blocked_count,
                'successful_samples': samples_count - blocked_count
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                'success': False,
                'reason': str(e)
            }
    
    def predict_quality(self, rsi_params: Dict, risk_params: Optional[Dict] = None) -> float:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            rsi_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RSI
            risk_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
        
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (0-1, –≥–¥–µ 1 = –æ—Ç–ª–∏—á–Ω–æ)
        """
        if not self.is_trained or not self.model:
            return 0.5  # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞
        
        try:
            features = self._extract_features(rsi_params, risk_params)
            features_scaled = self.scaler.transform(features)
            quality = self.model.predict(features_scaled)[0]
            return max(0.0, min(1.0, quality))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-1
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return 0.5
    
    def suggest_optimal_params(self, base_params: Dict, risk_params: Optional[Dict] = None,
                               num_suggestions: int = 10) -> List[Tuple[Dict, float]]:
        """
        –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏
        
        Args:
            base_params: –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            risk_params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
            num_suggestions: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ_–∫–∞—á–µ—Å—Ç–≤–æ)
        """
        if not self.is_trained:
            return []
        
        import random
        
        suggestions = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ
        for _ in range(num_suggestions * 5):  # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–æ–ª—å—à–µ, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à–∏–µ
            rsi_params = {
                'oversold': max(20, min(35, 
                    base_params.get('oversold', 29) + random.randint(-5, 5))),
                'overbought': max(65, min(80,
                    base_params.get('overbought', 71) + random.randint(-5, 5))),
                'exit_long_with_trend': max(55, min(70,
                    base_params.get('exit_long_with_trend', 65) + random.randint(-8, 8))),
                'exit_long_against_trend': max(50, min(65,
                    base_params.get('exit_long_against_trend', 60) + random.randint(-8, 8))),
                'exit_short_with_trend': max(25, min(40,
                    base_params.get('exit_short_with_trend', 35) + random.randint(-8, 8))),
                'exit_short_against_trend': max(30, min(45,
                    base_params.get('exit_short_against_trend', 40) + random.randint(-8, 8)))
            }
            
            quality = self.predict_quality(rsi_params, risk_params)
            suggestions.append((rsi_params, quality))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–∏–µ
        suggestions.sort(key=lambda x: x[1], reverse=True)
        return suggestions[:num_suggestions]

